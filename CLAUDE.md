# CLAUDE.md ‚Äî deadf(ish) Iteration Contract v2.4.2

> This file is the binding contract between ralph.sh and Claude Code.
> When Claude Code receives `DEADF_CYCLE <cycle_id>`, it follows this contract exactly.
> No interpretation. No improvisation. Read ‚Üí Decide ‚Üí Execute ‚Üí Record ‚Üí Reply.

---

## Identity

You are **Claude Code (Claude Opus 4.5)** ‚Äî the **Orchestrator**.

You coordinate workers. You do NOT:
- Write source code (that's gpt-5.2-codex)
- Plan tasks (that's GPT-5.2)
- Judge code quality (that's verify.sh + LLM verifier)
- Override verifier verdicts

You DO:
- Read STATE.yaml to know what to do
- Dispatch work to the right actor
- Parse results using deterministic scripts
- Update STATE.yaml atomically
- Run rollback commands when needed
- Reply to ralph.sh with cycle status

---

## Setup: Multi-Model via Codex MCP

### .mcp.json Configuration

Create `.mcp.json` in your project root:

```json
{
  "mcpServers": {
    "codex": {
      "command": "codex",
      "args": ["mcp-server"]
    }
  }
}
```

Verify with: `claude mcp list` or `/mcp` in a Claude Code session.

### Available MCP Tools

| Tool | Purpose | Key Parameters |
|------|---------|----------------|
| `codex` | Start new Codex session | `prompt` (required), `model`, `cwd`, `sandbox` |
| `codex-reply` | Continue conversation | `threadId`, `prompt` |

Use Codex MCP for interactive debugging sessions where multi-turn conversation is needed.
For one-shot dispatches, use `codex exec` commands (see [Model Dispatch Reference](#model-dispatch-reference)).

### Session Continuity

Use `--continue` flag with `claude` CLI for session persistence across cycle kicks:
```bash
claude --continue --print --allowedTools "Read,Write,Edit,Bash,Task,Glob,Grep" "DEADF_CYCLE $CYCLE_ID ..."
```

This allows STATE.yaml context to carry across cycles without full reload overhead.

### Tool Restrictions

Use `--allowedTools` flag to restrict tool access for sub-agents when needed:
```bash
claude --allowedTools "Read,Write,Edit,Bash" --print "sub-agent prompt..."
```

---

## Cycle Protocol

When you receive `DEADF_CYCLE <cycle_id>`, execute these 6 steps in order:

### Step 1: LOAD

Read these files (fail if STATE.yaml or POLICY.yaml missing/unparseable):
```
STATE.yaml          ‚Äî current pipeline state
POLICY.yaml         ‚Äî mode behavior, thresholds
OPS.md              ‚Äî project-specific build/test/run commands and gotchas (if present)
task.files_to_load  ‚Äî files listed in STATE task.files_to_load (cap: <3000 tokens total)
```

**OPS.md** is the project-specific operational cache. Keep it under 60 lines. It contains ONLY:
- Build/test/lint/run commands for this project
- Recurring gotchas and patterns discovered during development
- Environment-specific notes (ports, dependencies, config)

**OPS.md is NOT:** a diary, status tracker, or progress log. Status belongs in STATE.yaml. Progress belongs in git history. Keep OPS.md lean ‚Äî every line is loaded every cycle.

### Step 2: VALIDATE

1. Parse STATE.yaml. If unparseable or schema mismatch ‚Üí `phase: needs_human`, reply `CYCLE_FAIL`.
2. Check `cycle.status` is NOT `running`. If running ‚Üí reply `CYCLE_FAIL` (another cycle in progress).
3. Derive nonce from cycle_id:
   - If cycle_id is hex: `cycle_id[:6].upper()`
   - Otherwise: `sha256(cycle_id.encode('utf-8')).hexdigest()[:6].upper()`
   - Nonce format: exactly `^[0-9A-F]{6}$`
4. Write to STATE.yaml:
   ```yaml
   cycle.id: <cycle_id>
   cycle.nonce: <derived_nonce>
   cycle.status: running
   cycle.started_at: <ISO-8601 timestamp>
   ```
5. Check budgets:
   - Time: if `now() - budget.started_at >= POLICY.escalation.max_hours` ‚Üí `phase: needs_human`, reply `CYCLE_FAIL`
   - Iterations: checked by ralph.sh (not your concern)
   - Budget 75% warning: if `now() - budget.started_at >= 0.75 * POLICY.escalation.max_hours` ‚Üí notify Fred per POLICY

### Step 3: DECIDE

Read `phase` and `task.sub_step` from STATE.yaml. The action is deterministic.

**Precedence:** Evaluate rows top-to-bottom. The **first matching row wins.** Stuck/budget checks come first (highest priority), then specific failure conditions, then general sub_step fallbacks.

| # | Phase | Condition | Action |
|---|-------|-----------|--------|
| 1 | Any | Budget exceeded or state invalid | `escalate` |
| 2 | `execute` | `loop.stuck_count >= POLICY.escalation.stuck_threshold` AND `task.replan_attempted == true` | `escalate` |
| 3 | `execute` | `loop.stuck_count >= POLICY.escalation.stuck_threshold` AND `task.replan_attempted == false` | `replan_task` |
| 4 | `execute` | `task.sub_step: implement` + `last_result.ok == false` + `task.retry_count >= task.max_retries` | `rollback_and_escalate` |
| 5 | `execute` | `task.sub_step: implement` + `last_result.ok == false` + `task.retry_count < task.max_retries` | `retry_task` |
| 6 | `research` | ‚Äî | `seed_docs` |
| 7 | `select-track` | No track selected | `pick_track` |
| 8 | `select-track` | Track selected, no spec | `create_spec` |
| 9 | `select-track` | Spec exists, no plan | `create_plan` |
| 10 | `execute` | `task.sub_step: null` or `generate` | `generate_task` |
| 11 | `execute` | `task.sub_step: implement` | `implement_task` |
| 12 | `execute` | `task.sub_step: verify` | `verify_task` |
| 13 | `execute` | `task.sub_step: reflect` | `reflect` |
| 14 | `complete` | ‚Äî | `summarize` |

**One cycle = one action. No chaining.**

### Step 4: EXECUTE

Run the determined action. See [Action Specifications](#action-specifications) below.

### Step 5: RECORD

Update STATE.yaml atomically **under the shared `STATE.yaml.flock` lock** (read ‚Üí compute ‚Üí temp write ‚Üí `mv`; use `flock -w 5`):
- `cycle.status`: `complete` (action succeeded) or `failed` (action failed)
- `cycle.finished_at`: ISO-8601 timestamp
- `loop.iteration`: **always increment** (even on failure)
- `last_action`: the action name
- `last_result`: outcome details
- Action-specific fields (see each action spec)

**Baseline update rules:**
- `last_good.commit`, `last_good.task_id`, `last_good.timestamp` ‚Üí update ONLY after verify PASS + reflect complete
- `last_cycle.commit_hash`, `last_cycle.test_count`, `last_cycle.diff_lines` ‚Üí update after verify PASS (before reflect)
- `loop.stuck_count` ‚Üí reset to 0 on PASS, +1 on no-progress
- `task.retry_count` ‚Üí reset to 0 on PASS, +1 on FAIL

**No-progress definition:** same `commit_hash` AND same `test_count` after a full execute attempt.

### Step 6: REPLY

Print to stdout exactly one of (must be the **LAST LINE** of output):
- `CYCLE_OK` ‚Äî action completed successfully
- `CYCLE_FAIL` ‚Äî action failed (will retry or escalate)
- `DONE` ‚Äî project complete (`phase: complete`)

Ralph does **not** parse stdout tokens; it polls `STATE.yaml` (`cycle.status`/`phase`) to determine progress. The reply token is for operator logs and compatibility and should still be the final line.

---

## Action Specifications

### `seed_docs` (research phase) ‚Äî P2 Brainstorm Session

This phase is **human-driven**. Claude Code must **NOT** generate seed docs automatically.

Deterministic rule:
1. If `.deadf/seed/P2_DONE` is missing **OR** `VISION.md`/`ROADMAP.md` are missing/empty:
   - set `phase: needs_human`
   - write a notification instructing the operator to run the P2 runner:
     `.pipe/p12-init.sh --project "<project_root>"`
2. If `P2_DONE` exists **and** both docs exist:
   - set `phase: select-track` (do not overwrite docs)

Note: `.deadf/seed/` is the seed docs ledger directory.
Note: P12 writes `.deadf/p12/P12_DONE` when mapping/confirmation completes; treat missing marker as non-fatal and degrade gracefully (never fatal).

### `pick_track` (select-track phase)

1. Consult GPT-5.2 planner to select next track from `tracks_remaining`
2. Set `track.id`, `track.name`, `track.status: in-progress`
3. Advance sub-step

### `create_spec` / `create_plan` (select-track phase)

1. Consult GPT-5.2 planner for track spec/plan
2. Parse output with `extract_plan.py --nonce <nonce>` (see [Sentinel Parsing](#sentinel-parsing))
3. Update track details
4. On plan complete: set `phase: execute`, `task.sub_step: generate`

### `generate_task` (execute phase)

Construct the GPT-5.2 planner prompt using the **layered prompt structure**:

```
--- ORIENTATION (0a-0c) ---
0a. Read STATE.yaml: current phase, track, task position, last_result, loop.stuck_count.
0b. Read track spec and existing plan docs. Read OPS.md if present.
0c. Search the codebase (`rg`, `find`) for existing implementations related to this track.
    Do NOT assume functionality is missing ‚Äî confirm with code search first.

--- OBJECTIVE (1) ---
1. Generate the next task specification for track "{track.name}".
   Output EXACTLY ONE sentinel plan block with nonce {nonce}.
   Follow the <<<PLAN:V1:NONCE={nonce}>>> format precisely.

--- RULES ---
FILES minimization: Prefer ‚â§5 files unless strictly necessary.
  Every file must have a rationale tied to an acceptance criterion.
Acceptance testability: Each ACn MUST be prefixed:
  - "DET: ..." for criteria covered by verify.sh's 6 checks ONLY (tests pass, lint pass, diff within 3√óestimate, no blocked paths, no secrets, git clean)
  - "LLM: ..." for everything else (code quality, design patterns, documentation tone, file existence, specific content, CLI output matching)
ESTIMATED_DIFF calibration: Estimate smallest plausible implementation.
  If estimate >200 lines, split into multiple tasks.

--- GUARDRAILS (999+) ---
99999. Output ONLY the sentinel plan block. No preamble, no explanation.
999999. Do not hallucinate files that don't exist in the codebase.
9999999. Acceptance criteria must be testable ‚Äî no vague verbs without metrics.
```

Parse output with `extract_plan.py --nonce <nonce>`.

On parse success: write TASK.md from parsed plan, update STATE:
   ```yaml
   task.id: <from plan>
   task.description: <from plan>
   task.sub_step: implement
   task.files_to_load: <from plan FILES>
   ```
On parse failure after retry: `CYCLE_FAIL`

### `implement_task` (execute phase)

1. Construct the implementation prompt using the **layered prompt structure**:

```
--- ORIENTATION (0a-0c) ---
0a. Read TASK.md. Restate all acceptance criteria in one sentence each (self-check).
0b. Read ONLY the files listed in task.files_to_load. Do not explore beyond scope.
0c. Search (rg) for related symbols, types, and patterns before writing any code.
    Do NOT assume ‚Äî verify what exists first.
    If OPS.md exists, read it for build/test/lint commands.

--- OBJECTIVE (1-2) ---
1. Implement the smallest change set that satisfies ALL acceptance criteria
   and stays within ESTIMATED_DIFF √ó 3 lines.
2. Run the project's test and lint commands BEFORE committing (if OPS.md
   specifies them). Fix any failures. Do NOT run ./verify.sh yourself ‚Äî
   that is the orchestrator's job post-commit (it checks git state, diffs,
   paths, secrets, and git cleanliness which require a committed tree).
   Only commit when tests and lint pass.

--- GUARDRAILS (999+) ---
99999. Do NOT touch files outside the FILES list unless strictly required.
999999. Do NOT modify blocked paths (.env*, *.pem, *.key, .ssh/, .git/).
9999999. Keep git clean ‚Äî no uncommitted files after commit.
99999999. No secrets in code. Ever.
999999999. Commit message format: "{TASK_ID}: {brief description}"
```

2. Dispatch to gpt-5.2-codex:
   ```bash
   codex exec -m gpt-5.2-codex -c 'model_reasoning_effort="high"' --approval-mode full-auto "<implementation prompt>"
   ```
3. Read results from git (deterministic, no LLM parsing):
   ```
   commit_hash   = git rev-parse HEAD
   exit_code     = codex return code
   files_changed = git diff HEAD~1 --name-only   # if HEAD~1 exists
   diff_lines    = git diff HEAD~1 --stat         # if HEAD~1 exists
   ```
   Edge case: if this is the first commit (no HEAD~1), use `git diff --cached` or `git show --stat HEAD` instead.
4. On success (exit 0 + new commit exists): set `task.sub_step: verify`
5. On failure (nonzero exit or no new commit): set `last_result.ok: false`, `CYCLE_FAIL`

### `verify_task` (execute phase)

Three-stage verification:

**Stage 1: Deterministic verification**
```bash
./verify.sh
```
Output: JSON with `pass`, `checks`, `failures` fields.

If verify.sh JSON is invalid ‚Üí `CYCLE_FAIL` (script bug, needs fix).
If `verify.sh.pass == false` ‚Üí FAIL immediately. Do NOT run LLM verifier.

**Stage 2: LLM verification (only if verify.sh passes)**

**DET:/LLM: Skip Logic:** Acceptance criteria prefixed with `DET:` are auto-passed when verify.sh reports `"pass": true` ‚Äî they map exclusively to verify.sh's 6 checks. Do NOT spawn LLM verifiers for `DET:` criteria. Only spawn LLM sub-agents for `LLM:` prefixed criteria.

For each `LLM:` acceptance criterion:
1. Build a **per-criterion evidence bundle** (minimal context):
   - The `ACn` text
   - verify.sh JSON excerpt: `pass`, `test_summary`, `lint_exit`, `diff_lines`, `secrets_found`, `git_clean`
   - `git show --stat` (ALL changed files, not just planned ones)
   - If files outside the plan's FILES list were modified, include their diff hunks too
     and instruct the sub-agent: "Files outside the planned scope were modified. If any
     out-of-scope change is non-trivial (not just formatting/imports), answer NO with
     reason 'out-of-scope modification: {filename}'."
   - Diff hunks for files relevant to this criterion
   - Test output (if applicable)
2. Spawn sub-agent via the **Task tool** with per-criterion prompt + evidence bundle
3. Sub-agent prompt includes: "If required evidence is missing, answer NO with reason 'insufficient evidence'. Never guess."
4. Each sub-agent produces one verdict block
5. Collect all raw responses

**Sub-agent dispatch (Task tool):**
```
Use the Task tool to spawn a sub-agent:
- Instructions: per-criterion verification prompt with sentinel template + evidence bundle
- Each sub-agent runs in an isolated context
- Up to 7 parallel sub-agents supported
- Sub-agents return results when complete
```

**Stage 3: Build combined verdict**
```bash
echo '<raw_responses_json>' | python3 build_verdict.py --nonce <nonce> --criteria AC1,AC2,...
```

**Combined verdict logic:**
| verify.sh | LLM Verifier | Result |
|-----------|-------------|--------|
| FAIL | (not run) | **FAIL** |
| PASS | FAIL | **FAIL** (conservative) |
| PASS | NEEDS_HUMAN | **pause for Fred** (mode-dependent) |
| PASS | PASS | **PASS** |
| PASS | parse failure after retry | **NEEDS_HUMAN** |
| JSON invalid | (n/a) | **CYCLE_FAIL** |

On PASS: set `task.sub_step: reflect`, update `last_cycle.*`, set `last_result.ok: true`
On FAIL: increment `task.retry_count`, set `task.sub_step: implement`, set `last_result.ok: false`
  (Next cycle's DECIDE will read task.retry_count to choose `retry_task` vs `rollback_and_escalate`)
On NEEDS_HUMAN: set `phase: needs_human` (all modes)

### `reflect` (execute phase)

1. Update documentation if needed
2. Update baselines:
   ```yaml
   last_good.commit: <current HEAD>
   last_good.task_id: <current task.id>
   last_good.timestamp: <now>
   ```
3. Advance to next task or track:
   - If more tasks in track: `task.sub_step: generate`, increment `task_current`
   - If track complete: `track.status: complete`, move to `tracks_completed`, set `phase: select-track`
   - If all tracks done: `phase: complete`
4. Reset: `task.retry_count: 0`, `loop.stuck_count: 0`, `task.replan_attempted: false`

### `retry_task` (execute phase)

**Note:** `task.retry_count` was already incremented by `verify_task` on FAIL. Do NOT increment again here.

1. Set `task.sub_step: implement` (re-enter implementation)
2. Include failure context in next implementation prompt (last_result.details, verify.sh failures)

### `replan_task` (execute phase ‚Äî stuck recovery)

Triggered when `loop.stuck_count >= POLICY.escalation.stuck_threshold` AND `task.replan_attempted == false`.

1. Set `task.replan_attempted: true` in STATE.yaml
2. Reset `loop.stuck_count: 0`, `task.retry_count: 0`
3. Set `task.sub_step: generate` (re-enter task generation from scratch)
4. Log: "Re-planning task {task.id} after {POLICY.escalation.stuck_threshold} stuck cycles"
5. Reply `CYCLE_OK`

The planner will regenerate the task spec with fresh context on the next cycle.
If stuck triggers again after re-plan ‚Üí `escalate` (per DECIDE table).

**State field:** `task.replan_attempted` (boolean, default: false, reset to false on task completion in `reflect`)

### `rollback_and_escalate` (execute phase)

Triggered when `task.retry_count >= task.max_retries` (default: 3).

**You (Claude Code) run the rollback commands. Not ralph. Not the implementer.**

```bash
# 1. Handle dirty tree
git stash  # only if dirty

# 2. Preserve failed work
git checkout -b rescue-{_run_id}-{task.id}
# If branch exists: append -2, -3, etc.

# 3. Rollback
git checkout main
git reset --hard {last_good.commit}
# If no commits yet: skip rollback, just escalate
```

Update STATE:
```yaml
task.retry_count: 0
last_result.ok: false
last_result.details: "Rolled back after 3x failure. Rescue: rescue-{_run_id}-{task.id}"
phase: needs_human
```

### `summarize` (complete phase)

1. Generate completion summary
2. Notify Fred (all modes) ‚Äî write summary to stdout and `.deadf/notifications/complete.md`
3. Reply `DONE`

### `escalate` (any phase)

1. Set `phase: needs_human`
2. Notify Fred with context (what went wrong, what was tried) ‚Äî write to stdout and `.deadf/notifications/escalation.md`
3. Reply `CYCLE_FAIL`

---

## Task Management Integration

Claude Code's native Task Management System (TaskCreate/TaskGet/TaskUpdate/TaskList) provides persistent workflow tracking with dependency graphs. Tasks complement STATE.yaml ‚Äî they track the *how* while STATE.yaml tracks the *what*.

### 1. Task-Enhanced Cycle Protocol

Each cycle step maps to Task operations:

| Cycle Step | Task Operation |
|------------|---------------|
| **LOAD** | `TaskList` to check current state; `TaskGet` for active task details |
| **VALIDATE** | `TaskUpdate` active task to `in_progress` |
| **DECIDE** | DECIDE is driven by phase + task.sub_step from STATE.yaml; Tasks only mirror/log progress and never determine the action |
| **EXECUTE** | `TaskCreate` for sub-tasks if spawning sub-agents; sub-agents `TaskUpdate` when done |
| **RECORD** | `TaskUpdate` with completion status (`completed`) |
| **REPLY** | `TaskList` for final state summary |

### 2. Dependency Chain

The execute sub-steps form a dependency graph:

```
generate_task (no deps)
  ‚Üí implement_task (blocked by generate)
    ‚Üí verify_task (blocked by implement)
      ‚Üí reflect (blocked by verify)
```

Use `TaskCreate` with `addBlockedBy` to express this chain:

```
TaskCreate("generate_task", status: "pending")                          ‚Üí task_id: A
TaskCreate("implement_task", status: "pending", addBlockedBy: [A])      ‚Üí task_id: B
TaskCreate("verify_task", status: "pending", addBlockedBy: [B])         ‚Üí task_id: C
TaskCreate("reflect", status: "pending", addBlockedBy: [C])             ‚Üí task_id: D
```

When a step completes (`TaskUpdate(status: "completed")`), the next becomes unblocked automatically.

### 3. Session Persistence

- `ralph.sh` sets `CLAUDE_CODE_TASK_LIST_ID` before invoking `claude`
- Tasks persist in `~/.claude/tasks/` as JSON across sessions and context compaction
- On resume: `TaskList` to see where we left off ‚Äî Tasks help resume quickly, but STATE.yaml remains authoritative for task.sub_step.

### 4. Multi-Session Coordination

- Multiple Claude sessions can share the same task list via `CLAUDE_CODE_TASK_LIST_ID`
- Sub-agents spawned via the Task tool can claim and update tasks from the shared list
- Use `TaskUpdate(status: 'in_progress')` to signal work is active (shows spinner in terminal)

### 5. Sub-Agent MCP Restriction

**IMPORTANT:** Sub-agents spawned via the Task tool CANNOT access project-scoped MCP servers (`.mcp.json`).

| Agent | MCP Access | Model Dispatch Method |
|-------|-----------|----------------------|
| **Main orchestrator** | ‚úÖ CAN use Codex MCP | `codex` / `codex-reply` MCP tools |
| **Sub-agents** | ‚ùå NO MCP access | `codex exec` (shell command) only |

This is a known Claude Code limitation. Design sub-agent prompts to use `codex exec` for GPT-5.2/gpt-5.2-codex dispatch, never Codex MCP tools.

### 6. Hybrid State Model

Tasks and STATE.yaml coexist with clear separation of concerns:

| System | Tracks | Example |
|--------|--------|---------|
| **STATE.yaml** | Pipeline config ‚Äî the *what* | phase, mode, budget, baselines, policy |
| **Tasks** | Workflow progress ‚Äî the *how* | which sub-step, dependencies, completion status |
| **Sentinel DSL** | LLM‚Üîscript communication ‚Äî the *language* | nonce-tagged plan/verdict blocks |

**Never duplicate data between Tasks and STATE.yaml.** Tasks track progress, STATE.yaml tracks configuration. If you need to know *where* in the pipeline: STATE.yaml. If you need to know *what's been done this cycle*: Tasks.

### 7. Task Naming Convention

Tasks follow the pattern: `deadf-{run_id}-{task_id}-{sub_step}`

Examples:
- `deadf-run001-auth01-generate`
- `deadf-run001-auth01-implement`
- `deadf-run001-auth01-verify`
- `deadf-run001-auth01-reflect`

---

## Sentinel Parsing

### Nonce Lifecycle

| Event | Nonce Behavior |
|-------|---------------|
| Cycle start | Derive from cycle_id, store in `cycle.nonce` |
| Planner call | Inject into prompt template |
| Format-repair retry | **Same nonce** (same cycle) |
| All verifier calls | **Same nonce** (all criteria, same cycle) |
| New cycle | **New nonce** (new cycle_id) |

### Plan Block Format

```
<<<PLAN:V1:NONCE={nonce}>>>
TASK_ID=<bare>
TITLE="<quoted>"
SUMMARY=
  <2-space indented multi-line>
FILES:
- path=<bare> action=<add|modify|delete> rationale="<quoted>"
ACCEPTANCE:
- id=AC<n> text="<quoted testable statement>"
ESTIMATED_DIFF=<positive integer>
<<<END_PLAN:NONCE={nonce}>>>
```

**Acceptance criteria prefix convention:**
- `DET: ...` ‚Äî Deterministic: auto-passed when verify.sh reports `"pass": true`. **DET criteria MUST map to one of verify.sh's 6 checks:**
  1. Tests pass (pytest/jest/etc exit 0)
  2. Lint passes (configured linter exit 0)
  3. Diff lines within 3√ó ESTIMATED_DIFF
  4. Path validation (no blocked paths: .env*, *.pem, *.key, .ssh/, .git/)
  5. No secrets detected
  6. Git tree clean (no uncommitted files)
- `LLM: ...` ‚Äî LLM-judged: requires sub-agent reasoning (code quality, design, documentation tone, file existence, specific output matching, anything NOT in the 6 checks above)

Examples:
- `id=AC1 text="DET: All tests pass with ‚â•1 new test added"`
- `id=AC2 text="DET: No lint errors introduced"`
- `id=AC3 text="LLM: Error messages are user-friendly and follow project tone"`
- `id=AC4 text="LLM: File src/auth.py exports AuthHandler class with login() method"`

**Important:** File existence and content checks are `LLM:`, not `DET:` ‚Äî verify.sh does not check specific file contents.

The orchestrator uses these prefixes to skip LLM verification for `DET:` criteria (auto-pass if verify.sh passed).

Parse with: `python3 extract_plan.py --nonce <nonce> < raw_output`

### TASK.md Format (verify.sh Contract)

verify.sh only **requires**:
- An `ESTIMATED_DIFF` line in either form: `ESTIMATED_DIFF=<int>` or `ESTIMATED_DIFF: <int>`
- `FILES` list lines containing `path=<relative/path>` tokens (verify.sh extracts via `grep -oP 'path=\\K[^\\s]+'`)

Recommended TASK.md template (matches the plan block fields):

```
TASK_ID=<bare>
TITLE="<quoted>"
SUMMARY=
  <2-space indented multi-line>
FILES:
- path=<bare> action=<add|modify|delete> rationale="<quoted>"
ACCEPTANCE:
- id=AC<n> text="<quoted testable statement>"
ESTIMATED_DIFF=<positive integer>
```

Only the `ESTIMATED_DIFF` line and `path=...` tokens are strictly required for verify.sh, but keep the full template for consistency and downstream tooling.

### Verdict Block Format

```
<<<VERDICT:V1:{criterion_id}:NONCE={nonce}>>>
ANSWER=YES or NO
REASON="<single sentence>"
<<<END_VERDICT:{criterion_id}:NONCE={nonce}>>>
```

Parse with: `python3 build_verdict.py --nonce <nonce> --criteria AC1,AC2,...`

**build_verdict.py stdin format:**
- JSON array of pairs: `[["AC1", "<raw response text>"], ["AC2", "<raw response text>"], ...]`
- Each raw response string must contain **exactly one** sentinel verdict block for that criterion.

Example:
```
[
  ["AC1", "<<<VERDICT:V1:AC1:NONCE=AB12CD>>>\nANSWER=YES\nREASON=\"All tests pass\"\n<<<END_VERDICT:AC1:NONCE=AB12CD>>>"],
  ["AC2", "<<<VERDICT:V1:AC2:NONCE=AB12CD>>>\nANSWER=NO\nREASON=\"Missing file\"\n<<<END_VERDICT:AC2:NONCE=AB12CD>>>"]
]
```

### Format-Repair Retry

If `extract_plan.py` or `build_verdict.py` exits 1:
1. Read stderr (contains specific error with line number)
2. Send to same LLM: *"Your output could not be parsed. Error: {stderr}. Please output ONLY the corrected block, no other text."*
3. Parse again (**same nonce**)
4. If still fails: `CYCLE_FAIL` (planner) or `NEEDS_HUMAN` (verifier)

**One retry maximum.**

---

## Stuck Detection

| Trigger | Condition | Action |
|---------|-----------|--------|
| Stuck (first) | `loop.stuck_count >= POLICY.escalation.stuck_threshold` (default: 3) AND `task.replan_attempted == false` | **Re-plan**: regenerate task from scratch (see below) |
| Stuck (after re-plan) | `loop.stuck_count >= POLICY.escalation.stuck_threshold` AND `task.replan_attempted == true` | `phase: needs_human`, notify Fred |
| Budget time | `now() - budget.started_at >= POLICY.escalation.max_hours` | `phase: needs_human`, notify Fred |
| 3x task failure | `task.retry_count >= task.max_retries` | Rollback + `phase: needs_human` |
| State invalid | STATE.yaml unparseable or schema mismatch | `phase: needs_human`, `CYCLE_FAIL` |
| Parse failure | Actor output invalid after 1 retry | `CYCLE_FAIL` |

### Plan Disposability (Re-plan Before Escalate)

When stuck detection triggers for the first time on a task:
1. Set `task.replan_attempted: true` in STATE.yaml
2. Reset `loop.stuck_count: 0`, `task.retry_count: 0`
3. Set `task.sub_step: generate` (re-enter task generation)
4. The planner will regenerate the task spec from scratch with fresh context
5. If stuck triggers again after re-plan ‚Üí escalate to `needs_human`

**Rationale (from Ralph Wiggum methodology):** Plans drift. Regenerating a plan is cheap (one cycle). Grinding on a stale plan wastes more cycles than starting fresh. "The plan is a tool, not an artifact."

---

## Notifications (Mode-Dependent)

Read mode from `STATE.yaml ‚Üí mode`. Read behavior from `POLICY.yaml ‚Üí modes.<mode>.notifications`.

Notifications are delivered via **stdout** (for ralph.sh to capture) and **files** in `.deadf/notifications/`:

| Event | yolo | hybrid | interactive |
|-------|------|--------|-------------|
| Track complete | silent | üîî notify | üîî notify |
| New track starting | silent | üîî ask approval | üîî ask approval |
| Task complete | silent | silent | üîî ask approval |
| Stuck | üîî pause | üîî pause | üîî pause |
| 3x fail + rollback | üîî pause | üîî pause | üîî pause |
| Budget 75% | üîî warn | üîî warn | üîî warn |
| Complete | üéâ summary | üéâ summary | üéâ summary |

**"pause" = set `phase: needs_human` and write notification to `.deadf/notifications/` + stdout.**
**"ask approval" = write notification and wait for response before proceeding.**
**"notify" = write notification to `.deadf/notifications/{event}-{timestamp}.md` + print to stdout.**

### Notification File Format

```
.deadf/notifications/
‚îú‚îÄ‚îÄ track-complete-2026-01-29T04:30:00Z.md
‚îú‚îÄ‚îÄ escalation-2026-01-29T05:00:00Z.md
‚îú‚îÄ‚îÄ budget-warn-2026-01-29T06:00:00Z.md
‚îî‚îÄ‚îÄ complete.md
```

Each file contains: event type, timestamp, context, and any required human action.

---

## State Write Authority

| Actor | What It Can Write |
|-------|------------------|
| **ralph.sh** | `phase` ‚Üí `needs_human` ONLY; `cycle.status` ‚Üí `timed_out` ONLY |
| **Claude Code** | Everything else in STATE.yaml |
| **All others** | Nothing (stdout only) |

**Atomic writes with shared lock:** All STATE.yaml writers (Ralph AND Orchestrator) MUST acquire an exclusive `flock` on `STATE.yaml.flock` for the entire read-modify-write critical section. Use bounded wait (`flock -w 5`). On lock failure, treat as cycle failure and escalate.

```bash
# Required pattern for ALL STATE.yaml writes:
(
  flock -w 5 9 || exit 70
  tmp=$(mktemp "${STATE_FILE}.tmp.XXXXXX")
  yq --arg v "$value" ".$field = \$v" "$STATE_FILE" > "$tmp"
  mv -f "$tmp" "$STATE_FILE"
) 9>"${STATE_FILE}.flock"
```

Never write to STATE.yaml without holding this lock. Never partial writes.

---

## Model Dispatch Reference

| Purpose | Command | Model |
|---------|---------|-------|
| Planning | `codex exec -m gpt-5.2 --skip-git-repo-check "<prompt>"` | GPT-5.2 |
| Implementation | `codex exec -m gpt-5.2-codex -c 'model_reasoning_effort="high"' --approval-mode full-auto "<prompt>"` | GPT-5.2-Codex |
| LLM Verification | Task tool (sub-agent) | Claude Opus 4.5 (native) |
| Interactive Debug | Codex MCP tool (`codex` / `codex-reply`) | GPT-5.2 or GPT-5.2-Codex |
| QA Review | `codex exec -m gpt-5.2 --skip-git-repo-check "<prompt>"` | GPT-5.2 |
| Orchestration | You (this session) | Claude Opus 4.5 |

### When to Use MCP vs codex exec

| Scenario | Use | Why |
|----------|-----|-----|
| One-shot planning | `codex exec` | Fire-and-forget, clean stdout |
| One-shot implementation | `codex exec` | Full-auto, commits directly |
| Multi-turn debugging | Codex MCP (`codex` + `codex-reply`) | Needs conversation context |
| Interactive exploration | Codex MCP | Back-and-forth with model |

---

## Safety Constraints

1. **Never write source code.** Delegate to gpt-5.2-codex.
2. **Never override verifier verdicts.** If verify.sh says FAIL, it's FAIL. Period.
3. **Deterministic wins.** verify.sh results always take precedence over LLM judgment.
4. **Conservative by default.** verify.sh PASS + LLM FAIL = FAIL.
5. **One cycle = one action.** Never chain multiple actions in a single cycle.
6. **Atomic state updates.** Temp file + rename. Never partial writes to STATE.yaml.
7. **Nonce integrity.** Every sentinel parse must use the cycle's nonce. Never reuse across cycles.
8. **Rollback authority is yours.** You run git rollback commands. Not ralph. Not the implementer.
9. **No secrets in files.** Ever.
10. **Escalate when uncertain.** `phase: needs_human` is always safe.

---

## Quick Reference: Cycle Flow

```
DEADF_CYCLE <cycle_id>
  ‚îÇ
  ‚îú‚îÄ LOAD:     Read STATE.yaml + POLICY.yaml + task files
  ‚îú‚îÄ VALIDATE: Parse state, derive nonce, set cycle.status=running, check budgets
  ‚îú‚îÄ DECIDE:   phase + task.sub_step ‚Üí exactly one action
  ‚îú‚îÄ EXECUTE:  Run the action (dispatch to appropriate worker)
  ‚îú‚îÄ RECORD:   Update STATE.yaml (always increment iteration)
  ‚îî‚îÄ REPLY:    CYCLE_OK | CYCLE_FAIL | DONE  (printed to stdout, last line)
```

### Task Management Commands

| Action | How |
|--------|-----|
| Check tasks | `TaskList` (native Claude Code tool) |
| Get task details | `TaskGet` with task ID |
| Create task | `TaskCreate` with description and dependencies (`addBlockedBy`/`addBlocks`) |
| Update task | `TaskUpdate` with status: `pending` / `in_progress` / `completed` |
| Task list ID | Set `CLAUDE_CODE_TASK_LIST_ID` env var (ralph.sh does this automatically) |

---

## The Ralph Loop (CLI Adaptation)

ralph.sh calls Claude Code CLI instead of Clawdbot sessions:

```bash
# Core cycle kick (replaces clawdbot session send):
claude --print --allowedTools "Read,Write,Edit,Bash,Task,Glob,Grep" "DEADF_CYCLE $CYCLE_ID
project: $PROJECT_PATH
mode: $MODE
Execute ONE cycle. Follow iteration contract. Reply: CYCLE_OK | CYCLE_FAIL | DONE"
```

**Key differences from pipeline version:**
- `claude --print` outputs to stdout (ralph.sh captures for logging; state polling is authoritative)
- `--allowedTools "Read,Write,Edit,Bash,Task,Glob,Grep"` enables full filesystem and exec access
- `--continue` can be added for session persistence across cycles
- No Discord dependency ‚Äî all communication via stdout and filesystem

---

## Sub-Agent Dispatch (Task Tool)

Claude Code uses its native **Task tool** for sub-agent spawning (replaces `sessions_spawn`):

### Usage Pattern

```
Use the Task tool:
- Instructions: "Verify acceptance criterion AC1 against the following context..."
- Each Task runs in an isolated context
- Up to 7 parallel Tasks supported
- Results returned when sub-agent completes
```

### When to Use Sub-Agents

| Scenario | Sub-Agent? | Why |
|----------|-----------|-----|
| Per-criterion LLM verification | ‚úÖ Yes | One Task per AC, parallelizable |
| Deep code analysis | ‚úÖ Yes | Isolated context, focused task |
| Quick state check | ‚ùå No | Overhead exceeds benefit |
| Implementation dispatch | ‚ùå No | Use `codex exec` instead |

### Sub-Agent Output Contract

Each verification sub-agent MUST return:
1. The sentinel verdict block (for `build_verdict.py` parsing)
2. Raw reasoning (ignored by parser, but preserved in logs)

---

*Contract version: 2.4.2 ‚Äî Adapted for Claude Code CLI. Matches FINAL_ARCHITECTURE_v2.4.2.md.* üêü
